{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep\n",
    "論文リンク：https://arxiv.org/pdf/1606.07792.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from configparser import ConfigParser\n",
    "from time import time, gmtime, strftime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils import EarlyStoppingHook\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# configファイルの読み込み\n",
    "config_filename = './config/WideAndDeep_config.ini'\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read(config_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['train']['filename_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラムの定義\n",
    "HEADER = ['user_id', 'item_id', 'rating']\n",
    "HEADER_DEFAULTS = [['0'], ['0'], ['0']]\n",
    "\n",
    "FEATURE_NAMES = ['user_id', 'item_id']\n",
    "CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE = {\n",
    "  'user_id': int(config['model']['user_bucket_size']),\n",
    "  'item_id' : int(config['model']['item_bucket_size'])\n",
    "  }\n",
    "\n",
    "USED_FEATURE_NAMES = ['user_id', 'item_id', 'rating']\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES =  list(CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE.keys())\n",
    "TARGET = 'rating'\n",
    "TARGET_LABELS = ['0','1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input_config(config, phase):\n",
    "    '''iniファイルをパースする関数\n",
    "    configparserで数値を引っ張るとstrになってしまうためここでintに変換している。\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "    config: dict\n",
    "        phaseごとの設定を記した辞書\n",
    "    phase: str\n",
    "        学習のフェーズ\n",
    "        {'train', 'eval', 'predict'}のいずれか1つを指定\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "    filename_pattern: string\n",
    "    batch_size: int\n",
    "        学習時のバッチサイズ\n",
    "    num_epochs: int\n",
    "        学習で回す最大のepoch数\n",
    "    skip_header_lines: int\n",
    "        csvファイルのうち読み飛ばす行数\n",
    "    '''\n",
    "    filename_pattern = config[phase]['filename_pattern']\n",
    "    batch_size = int(config[phase]['batch_size'])\n",
    "    num_epochs = int(config[phase]['num_epochs']) # Noneにすると評価したが最後一生返ってこない\n",
    "    skip_header_lines = int(config[phase]['skip_header_lines'])\n",
    "\n",
    "    return filename_pattern, batch_size, num_epochs, skip_header_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_row(csv_row):\n",
    "    '''csvをparseする関数\n",
    "    csv_input_fn内で使用\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "    csv_row: Tensor\n",
    "        string型の入力\n",
    "    \n",
    "    Returns\n",
    "    --------------------\n",
    "    features, target: Tensorのlist\n",
    "        record_defaultsに指定された型と同じデータ型が期待される\n",
    "    '''\n",
    "    columns = tf.decode_csv(csv_row, record_defaults=HEADER_DEFAULTS)\n",
    "    features = dict(zip(HEADER, columns))\n",
    "\n",
    "    target = features.pop(TARGET)\n",
    "    return features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_input_fn(config, phase, mode=tf.estimator.ModeKeys.EVAL):\n",
    "    '''csvからfeaturesとtargetを出力するinput_fnを返す関数\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "    config: dict\n",
    "        phaseごとの設定を記した辞書\n",
    "    phase: str\n",
    "        学習のフェーズ\n",
    "        {'train', 'eval', 'predict'}のいずれか1つを指定\n",
    "    mode: tf.estimator.ModeKeys\n",
    "        学習のフェーズとほぼ同値（諸々の事情でphaseと分けている）\n",
    "        \n",
    "    Returns\n",
    "    --------------------\n",
    "    features, target: Iterator\n",
    "        バッチの大きさだけ特徴量・目的変数を返すイテレータ\n",
    "    '''\n",
    "    filename_pattern, batch_size, num_epochs, skip_header_lines = parse_input_config(config, phase)\n",
    "\n",
    "    # ファイル名のパターンを元にデータの読み込み\n",
    "    file_names = tf.matching_files(filename_pattern)\n",
    "    dataset = tf.data.TextLineDataset(filenames=file_names)\n",
    "    dataset = dataset.skip(skip_header_lines)\n",
    "    \n",
    "    shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(int(config[phase]['batch_size']) * 2,\n",
    "                                  seed=0,\n",
    "                                  reshuffle_each_iteration=True)\n",
    "\n",
    "    # バッチサイズ分だけ切り出しgenerateする\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda csv_row: parse_csv_row(csv_row))\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features, target = iterator.get_next()\n",
    "    \n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_serving_input_fn():\n",
    "    '''serving用のinput_fn\n",
    "        \n",
    "    Returns\n",
    "    --------------------\n",
    "    tf.estimator.export.ServingInputReceiver: Tensor\n",
    "    '''\n",
    "    receiver_tensor = {}\n",
    "    for feature_name in USED_FEATURE_NAMES:\n",
    "        dtype = tf.float32 if feature_name == TARGET else tf.string\n",
    "        receiver_tensor[feature_name] = tf.placeholder(shape=[None], dtype=dtype)\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(receiver_tensor, receiver_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = lambda: csv_input_fn(config=config, \n",
    "                                      phase='train', \n",
    "                                      mode=tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "eval_input_fn = lambda: csv_input_fn(config=config,\n",
    "                                     phase='eval', \n",
    "                                     mode=tf.estimator.ModeKeys.EVAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn,\n",
    "                  max_steps=int(config['train']['max_steps']),\n",
    "                  hooks=[EarlyStoppingHook(int(config['model']['early_stop']))]\n",
    "                  )\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn,\n",
    "                exporters=[tf.estimator.LatestExporter(name=\"estimate\",  \n",
    "                                                       serving_input_receiver_fn=json_serving_input_fn)],\n",
    "                steps=None,\n",
    "                throttle_secs = 15\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_execute_time = gmtime()\n",
    "execute_time = strftime(\"%Y%m%d_%H%M%S\", raw_execute_time )\n",
    "model_dir = os.path.join(config['path']['model_dir'], execute_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig().replace(model_dir=model_dir, save_checkpoints_secs=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_feature_dim = int(config['model']['wide_feature_dim'])\n",
    "user_embedding_dim = int(config['model']['user_embedding_dim'])\n",
    "item_embedding_dim = int(config['model']['item_embedding_dim'])\n",
    "\n",
    "categorical_hash_user = \\\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('user_id', CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE['user_id'])\n",
    "categorical_hash_item = \\\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('item_id', CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE['item_id'])\n",
    "\n",
    "categorical_feature_user_x_categorical_feature_item = tf.feature_column.crossed_column(['user_id', 'item_id'], wide_feature_dim)\n",
    "categorical_feature_user_emb = tf.feature_column.embedding_column(\n",
    "    categorical_column=categorical_hash_user, dimension=user_embedding_dim)\n",
    "categorical_feature_item_emb = tf.feature_column.embedding_column(\n",
    "    categorical_column=categorical_hash_item, dimension=item_embedding_dim)\n",
    "\n",
    "wide_feature_columns = [categorical_feature_user_x_categorical_feature_item]\n",
    "deep_feature_columns = [categorical_feature_user_emb, categorical_feature_item_emb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_prob = float(config['model']['dropout_prob'])\n",
    "hidden_units = [64, 32]\n",
    "\n",
    "estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
    "                        n_classes= len(TARGET_LABELS),\n",
    "                        label_vocabulary=TARGET_LABELS,\n",
    "                        dnn_feature_columns = deep_feature_columns,\n",
    "                        linear_feature_columns = wide_feature_columns,\n",
    "                        dnn_hidden_units= hidden_units,\n",
    "                        dnn_optimizer= tf.train.AdamOptimizer(),\n",
    "                        dnn_activation_fn= tf.nn.relu,\n",
    "                        dnn_dropout= dropout_prob,\n",
    "                        model_dir=model_dir,\n",
    "                        config= run_config\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測&評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(config['predict']['filename_pattern'])\n",
    "test_size = len(test_data)\n",
    "\n",
    "predict_input_fn = lambda: csv_input_fn(config=config, \n",
    "                                      phase='predict', \n",
    "                                      mode=tf.estimator.ModeKeys.PREDICT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = estimator.predict(input_fn=predict_input_fn)\n",
    "values = list(map(lambda item: item[\"logistic\"][0],list(itertools.islice(predictions, test_size))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value = np.array(test_data.iloc[:,2])\n",
    "pred_value = np.array(values)\n",
    "pred_value_binary = np.round(pred_value)\n",
    "\n",
    "auc = roc_auc_score(test_value, pred_value)\n",
    "accuracy = accuracy_score(test_value, pred_value_binary)\n",
    "print('AUC: {:.4f}\\nAccuracy: {:.4f}'.format(auc, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
