{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分類用データセット作成Notebook\n",
    "MovieLensには正例（実際にCVしたレコード）しか含まれていないためネガティブサンプルを作成する。   \n",
    "またTrain/Eval/Testで分割するときにtimestampでソートしてから適当な数で分割することとしている（今回はTrain:Eval:Test=7:2:1ぐらいの比率で分割）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_dataset = pd.read_csv('../data/org_20m/ratings.csv', names=['user','item','rating','timestamp'], skiprows=1)\n",
    "#rec_dataset = pd.read_csv('../data/u.data', sep='\\t',\n",
    "                         #header=None,\n",
    "                         #names=['user','item','rating','timestamp'])\n",
    "rec_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset size: {}'.format(len(rec_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のデータ数でサンプルを作成する（以下はそれぞれの数字／実際はこれの倍の大きさ）   \n",
    "\n",
    "- MovieLens20M\n",
    "    - Train: 14,000,000    \n",
    "    - Eval: 4,000,000    \n",
    "    - Test: 2,000,263\n",
    "- MovieLens100k\n",
    "    - Train: 70,000\n",
    "    - Eval: 20,000\n",
    "    - TestL 10,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ユーザ・アイテムの組み合わせを適当に作成する関数   \n",
    "ユーザ・アイテムの辞書を作成しておき、適当に作成された組み合わせがその中に存在していなければリストに加えるというもの。   \n",
    "ここで作成したリストはあとでDataFrameに変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_combinations(df):\n",
    "    pos_set = set(df.iloc[:,:2].itertuples(index=False, name=None))\n",
    "    user_list = df.user.unique()\n",
    "    item_list = df.item.unique()\n",
    "    neg_user = []\n",
    "    neg_item = []\n",
    "    \n",
    "    while len(neg_user) < len(df):\n",
    "        new_user = random.choice(user_list)\n",
    "        new_item = random.choice(item_list)\n",
    "        new_sample = (new_user, new_item)\n",
    "        if new_sample not in pos_set:\n",
    "            neg_user.append(new_user)\n",
    "            neg_item.append(new_item)\n",
    "    return neg_user, neg_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "neg_user, neg_item = create_random_combinations(rec_dataset)\n",
    "t2 = time()\n",
    "print('{:.4f} seconds elapsed'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(np.concatenate([np.array(neg_user).reshape(-1,1),\n",
    "                         np.array(neg_item).reshape(-1,1),\n",
    "                         np.zeros(len(neg_user)).reshape(-1,1)\n",
    "                        ], axis=1),\n",
    "                      columns=['user','item','rating'])\n",
    "\n",
    "neg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型を整える\n",
    "neg_df.iloc[:,0] = neg_df.iloc[:,0].map(int).map(str)\n",
    "neg_df.iloc[:,1] = neg_df.iloc[:,1].map(int).map(str)\n",
    "neg_df.iloc[:,2] = neg_df.iloc[:,2].map(int)\n",
    "neg_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元のデータをpositiveデータとするためratingを1.0に変更しdf化\n",
    "\n",
    "pos_df = rec_dataset.sort_values('timestamp').iloc[:,:3]\n",
    "del rec_dataset\n",
    "\n",
    "# データ型を整える\n",
    "pos_df.iloc[:,0] = pos_df.iloc[:,0].map(int).map(str)\n",
    "pos_df.iloc[:,1] = pos_df.iloc[:,1].map(int).map(str)\n",
    "pos_df.iloc[:,2] = pos_df.iloc[:,2].map(int)\n",
    "pos_df.loc[:,'rating'] = 1\n",
    "\n",
    "pos_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train用のデータセット作成\n",
    "train_file_name = '../data/MovieLens20M/classification/train20m.csv'\n",
    "pos_df_train = pos_df.iloc[:14000000,:]\n",
    "neg_df_train = neg_df.iloc[:14000000,:]\n",
    "\n",
    "# 特に意味はないが固まっているのが気になるためランダムソートしている\n",
    "dataset_train = pd.concat([pos_df_train, neg_df_train], axis=0).sample(frac=1).reset_index(drop=True)\n",
    "dataset_train.to_csv(train_file_name, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval用のデータセット作成\n",
    "eval_file_name = '../data/MovieLens20M/classification/eval20m.csv'\n",
    "pos_df_eval = pos_df.iloc[14000000:18000000,:]\n",
    "neg_df_eval = neg_df.iloc[14000000:18000000,:]\n",
    "\n",
    "dataset_eval = pd.concat([pos_df_eval, neg_df_eval], axis=0).sample(frac=1).reset_index(drop=True)\n",
    "dataset_eval.to_csv(eval_file_name, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test用のデータセット作成\n",
    "test_file_name = '../data/MovieLens20M/classification/test20m.csv'\n",
    "pos_df_test = pos_df.iloc[18000000:,:]\n",
    "neg_df_test = neg_df.iloc[18000000:,:]\n",
    "\n",
    "dataset_test = pd.concat([pos_df_test, neg_df_test], axis=0).sample(frac=1).reset_index(drop=True)\n",
    "dataset_test.to_csv(test_file_name, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中身の確認\n",
    "filename = test_file_name\n",
    "check_df = pd.read_csv(filename)\n",
    "print('Dataset size: {}'.format(len(check_df)))\n",
    "print(check_df.dtypes)\n",
    "check_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数がstrでなければならない場合があるため一旦別ファイルを作成\n",
    "# 入っているレコードは同じ\n",
    "train_file_name = '../data/MovieLens20M/classification/train20m.csv'\n",
    "train_file_name_str = '../data/MovieLens20M/classification_str/train20m.csv'\n",
    "tmp_df = pd.read_csv(train_file_name)\n",
    "tmp_df.iloc[:,-1] = tmp_df.iloc[:,-1].map(str)\n",
    "tmp_df.to_csv(train_file_name_str, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "eval_file_name = '../data/MovieLens20M/classification/eval20m.csv'\n",
    "eval_file_name_str = '../data/MovieLens20M/classification_str/eval20m.csv'\n",
    "tmp_df = pd.read_csv(eval_file_name)\n",
    "tmp_df.iloc[:,-1] = tmp_df.iloc[:,-1].map(str)\n",
    "tmp_df.to_csv(eval_file_name_str, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_file_name = '../data/MovieLens20M/classification/test20m.csv'\n",
    "test_file_name_str = '../data/MovieLens20M/classification_str/test20m.csv'\n",
    "tmp_df = pd.read_csv(test_file_name)\n",
    "tmp_df.iloc[:,-1] = tmp_df.iloc[:,-1].map(str)\n",
    "tmp_df.to_csv(test_file_name_str, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
